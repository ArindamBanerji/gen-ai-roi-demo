# SOC Copilot Demo â€” v2.5 / v3.0 Design Document

**Version:** 1.0
**Date:** February 17, 2026
**Status:** Draft â€” Design Phase
**Audience:** Internal (development planning, VC pitch preparation, partner enablement)
**Prerequisite:** v2.0 complete and tagged (feature/v2-enhancements merged to main)

---

## Executive Summary

v2.0 proved the architecture and added CISO-facing business impact. v2.5 adds **interactivity and domain depth** â€” the prospect can input their own numbers (ROI Calculator), see decisions learn from outcomes (Feedback Loop), watch the system resolve competing policies, and experience a smarter query layer. v3.0 adds **platform depth** â€” full reinforcement learning on the decision graph, external context ingestion, process intelligence integration, and compliance-grade audit trails.

The organizing principle: **v2.5 makes the demo personally relevant to each prospect. v3.0 makes it architecturally unassailable.**

---

## Current State (v2.0 â€” Complete)

| Capability | Where | Status |
|---|---|---|
| Two learning loops (Situation Analyzer + AgentEvolver) | Tabs 2, 3 | âœ… |
| Decision economics (time/cost/risk per option) | Tab 3 | âœ… |
| Operational impact narrative ($4,800/mo savings) | Tab 2 | âœ… |
| Business impact banner (847 hrs, $127K) | Tab 4 | âœ… |
| Two-loop hero diagram | Tab 4 | âœ… |
| Blocking demo (eval gate failure) | Tab 2 | âœ… |
| Two alert types (travel login + phishing) | Tab 3 | âœ… |

### What's Missing (the v2.5/v3 gaps)

| Gap | Why It Matters | Version |
|---|---|---|
| Prospect can't input THEIR numbers | Demo feels generic, not personal | v2.5 |
| Decisions don't learn from outcomes | "Cool architecture but does it actually learn?" | v2.5 |
| No policy conflict handling | CISOs live with conflicting policies daily | v2.5 |
| Queries can't recover from exec mistakes | Execs type vague prompts, get confused | v2.5 |
| No external context sources | Graph feels static, not alive | v3.0 |
| No compliance/audit trail | CISOs report to boards quarterly | v3.0 |
| No process intelligence | Can't show workflow optimization | v3.0 |
| Single-domain (SOC only) | VCs want to see platform, not point solution | v3.0 |

---

## SECTION 1: v2.5 â€” Interactive Demo with Domain Depth

**Theme:** "Make it personal. Make it learn. Make it resolve conflict."
**Estimated effort:** 8-12 prompts across 2-3 sessions
**Target:** Demoable in partner meetings, prospect-specific

---

### 1A. ROI Calculator

**Priority:** Highest â€” the single strongest CISO closer for partner meetings.

**The Problem:** The impact banner shows OUR numbers (847 hours, $127K). A CISO watching thinks: "Those are your assumptions. What about MY SOC?"

**The Solution:** An interactive calculator where the prospect inputs their environment, and the demo projects savings using their numbers.

#### UI Design

New component â€” either a modal triggered from Tab 4's impact banner, or a dedicated fifth tab. Modal is recommended (keeps 4-tab structure, feels like a natural extension of Tab 4).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ’° ROI CALCULATOR â€” Your SOC, Your Numbers            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  YOUR ENVIRONMENT                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Alerts per day:        [____500____] â—„ sliderâ”‚       â”‚
â”‚  â”‚ SOC analysts:          [_____8_____] â—„ sliderâ”‚       â”‚
â”‚  â”‚ Avg analyst salary:    [___$85,000__] â—„ inputâ”‚       â”‚
â”‚  â”‚ Current MTTR (min):    [____18_____] â—„ sliderâ”‚       â”‚
â”‚  â”‚ Current auto-close %:  [____35%____] â—„ sliderâ”‚       â”‚
â”‚  â”‚ Avg escalation cost:   [___$150____] â—„ inputâ”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  PROJECTED IMPACT (with SOC Copilot)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                                             â”‚       â”‚
â”‚  â”‚  Auto-close rate:    35% â†’ 89%  (+54 pts)   â”‚       â”‚
â”‚  â”‚  MTTR:               18 min â†’ 4.5 min       â”‚       â”‚
â”‚  â”‚  Alerts auto-handled: 445/day (was 175)     â”‚       â”‚
â”‚  â”‚  Analyst hours freed: 1,240/month           â”‚       â”‚
â”‚  â”‚                                             â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚       â”‚
â”‚  â”‚  â”‚  ANNUAL SAVINGS: $1.26M               â”‚  â”‚       â”‚
â”‚  â”‚  â”‚  Payback period: 6 weeks              â”‚  â”‚       â”‚
â”‚  â”‚  â”‚  ROI: 8.4x in Year 1                 â”‚  â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚       â”‚
â”‚  â”‚                                             â”‚       â”‚
â”‚  â”‚  Breakdown:                                 â”‚       â”‚
â”‚  â”‚  â€¢ Analyst time recovered: $892K/yr         â”‚       â”‚
â”‚  â”‚  â€¢ Reduced escalation cost: $234K/yr        â”‚       â”‚
â”‚  â”‚  â€¢ Compliance automation: $134K/yr          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  [ðŸ“„ Export as PDF]  [ðŸ“§ Email Summary]                â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Calculation Logic

```
# Inputs (from sliders)
alerts_per_day = 500
analysts = 8
salary = 85000
current_mttr = 18
current_auto_close = 0.35
escalation_cost = 150

# Constants (from our demo data)
projected_auto_close = 0.89
projected_mttr = current_mttr * 0.25  # 75% reduction
monthly_alerts = alerts_per_day * 30

# Calculations
new_auto_handled = monthly_alerts * projected_auto_close
old_auto_handled = monthly_alerts * current_auto_close
additional_auto_handled = new_auto_handled - old_auto_handled

analyst_hourly = salary / 2080  # $40.87/hr at $85K
minutes_saved_per_alert = current_mttr - projected_mttr  # 13.5 min
hours_freed_monthly = (additional_auto_handled * minutes_saved_per_alert) / 60

annual_analyst_savings = hours_freed_monthly * 12 * analyst_hourly
annual_escalation_savings = additional_auto_handled * 12 * escalation_cost * 0.15  # 15% were escalations
annual_compliance_savings = analysts * 5000  # estimated compliance automation per analyst

total_annual = annual_analyst_savings + annual_escalation_savings + annual_compliance_savings
```

#### Implementation Plan

| Prompt | Scope | Files |
|---|---|---|
| 7A | Backend: `/api/roi/calculate` endpoint accepting inputs, returning projections | `backend/app/routers/roi.py` |
| 7B | Frontend: ROI Calculator modal component with sliders and live calculation | `frontend/src/components/ROICalculator.tsx` |
| 7C | Frontend: "Calculate Your ROI" button on Tab 4 + PDF export | `CompoundingTab.tsx` + export utility |

---

### 1B. Outcome Feedback Loop (Simplified Loop 3)

**Priority:** High â€” answers "does it actually learn from being wrong?"

**The Problem:** The demo shows the system making decisions and shows how it evolves prompt variants. But it never shows what happens when a decision turns out to be WRONG. CISOs immediately ask: "What if it auto-closes something that was actually a real threat?"

**The Solution:** After "Apply Recommendation" in Tab 3, add an "Outcome Feedback" step that lets the demo show:
1. Correct outcome â†’ graph strengthens (edge weights increase, pattern confidence rises)
2. Incorrect outcome â†’ graph weakens (confidence drops, pattern flagged, analyst alerted)

#### UI Design (Tab 3 addition)

After the current "Closed Loop Execution" section, add:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“Š OUTCOME FEEDBACK (Loop 3: Learning from Results)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  24 hours later â€” was this decision correct?            â”‚
â”‚                                                         â”‚
â”‚  [âœ… Confirmed Correct]    [âŒ Incorrect â€” Real Threat] â”‚
â”‚                                                         â”‚
â”‚  â”€â”€ If "Confirmed Correct" clicked: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                         â”‚
â”‚  Graph Update:                                          â”‚
â”‚  â€¢ PAT-TRAVEL-001 confidence: 94% â†’ 94.3% (+0.3)      â”‚
â”‚  â€¢ Edge weight (Userâ†’TravelContext): 0.91 â†’ 0.93       â”‚
â”‚  â€¢ Decision added to precedent library (128 total)      â”‚
â”‚  â€¢ "This pattern is now 0.3% more trusted"              â”‚
â”‚                                                         â”‚
â”‚  â”€â”€ If "Incorrect" clicked: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                         â”‚
â”‚  âš ï¸ ALERT: Decision outcome negative                    â”‚
â”‚  â€¢ PAT-TRAVEL-001 confidence: 94% â†’ 88% (-6.0)        â”‚
â”‚  â€¢ Threshold review triggered for auto-close actions    â”‚
â”‚  â€¢ Analyst notification sent: "Review travel alerts"    â”‚
â”‚  â€¢ Next 5 travel alerts will route to Tier 2            â”‚
â”‚  â€¢ "System is self-correcting â€” it learned from this"   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key Demo Narrative

The CISO asks: "What if it's wrong?"

You click "Incorrect â€” Real Threat" and say:

> "Watch what happens. Confidence drops 6 points. The next five similar alerts automatically route to a human. The system didn't just fail â€” it learned from the failure. And it told your team why. That's the difference between a static playbook and a learning system."

This is devastatingly effective because it directly addresses the #1 CISO fear (automated system missing a real threat) and turns it into a strength.

#### Backend Design

```python
# New endpoint: POST /api/alert/outcome
# Request: { decision_id: str, outcome: "correct" | "incorrect" }
# Response: {
#   graph_updates: [
#     { node: "PAT-TRAVEL-001", field: "confidence", before: 0.94, after: 0.943 },
#     { edge: "Userâ†’TravelContext", field: "weight", before: 0.91, after: 0.93 }
#   ],
#   consequence: "Pattern strengthened" | "Threshold review triggered",
#   next_n_alerts_override: null | { action: "escalate_tier2", count: 5 },
#   narrative: "..."
# }
```

#### Implementation Plan

| Prompt | Scope | Files |
|---|---|---|
| 8A | Backend: `/api/alert/outcome` endpoint with graph update logic + narrative | `backend/app/routers/triage.py` + `backend/app/services/feedback.py` |
| 8B | Frontend: Outcome Feedback panel in Tab 3 with two buttons + result display | `AlertTriageTab.tsx` |

---

### 1C. Policy Conflict Resolution

**Priority:** High â€” extremely practical for CISOs who deal with conflicting policies daily.

**The Problem:** Real SOC example:
- Policy A: "Auto-close travel alerts with VPN match" (efficiency)
- Policy B: "Escalate all alerts for users with risk score > 0.80" (security)
- John Smith: VP Finance (risk 0.85), traveling to Singapore, VPN matches â†’ BOTH policies apply and CONFLICT

**The Solution:** The Situation Analyzer detects the conflict, shows both policies, explains the resolution, and logs it for audit.

#### UI Design (Tab 3 â€” enhancement to Situation Analyzer)

When a policy conflict exists, add a section between Situation Analysis and Recommendation:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âš–ï¸ POLICY CONFLICT DETECTED                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Two policies apply to this alert:                      â”‚
â”‚                                                         â”‚
â”‚  Policy A: AUTO-CLOSE-TRAVEL          Priority: 3       â”‚
â”‚  "Auto-close travel anomaly alerts    Scope: All users  â”‚
â”‚   when VPN matches travel record"     Status: Active    â”‚
â”‚                                                         â”‚
â”‚  Policy B: ESCALATE-HIGH-RISK         Priority: 1 â˜…    â”‚
â”‚  "Escalate all alerts for users       Scope: Risk > 0.8 â”‚
â”‚   with risk score above 0.80"         Status: Active    â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ RESOLUTION: Policy B takes precedence          â”‚     â”‚
â”‚  â”‚                                                â”‚     â”‚
â”‚  â”‚ Reason: Higher priority (1 vs 3) AND           â”‚     â”‚
â”‚  â”‚ security-first principle â€” when efficiency      â”‚     â”‚
â”‚  â”‚ and security conflict, security wins.           â”‚     â”‚
â”‚  â”‚                                                â”‚     â”‚
â”‚  â”‚ Action adjusted: ESCALATE_TIER2 (was: auto-    â”‚     â”‚
â”‚  â”‚ close). Analyst will review with full context.  â”‚     â”‚
â”‚  â”‚                                                â”‚     â”‚
â”‚  â”‚ Audit: Conflict logged as CON-2026-0847        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Why This Matters

1. **CISOs recognize this instantly** â€” they deal with policy conflicts weekly
2. **Audit trail** â€” every conflict resolution is logged with reasoning (SOC2/NIST requirement)
3. **Demonstrates graph reasoning** â€” policies are graph nodes, conflict detection is graph traversal
4. **Differentiator** â€” no SIEM does this; they just execute the first matching rule

#### Backend Design

```python
# New in situation.py or new file policy.py
POLICIES = {
    "POL-AUTO-CLOSE-TRAVEL": {
        "action": "false_positive_close",
        "conditions": {"alert_type": "anomalous_login", "travel_match": True},
        "priority": 3,
        "scope": "all_users"
    },
    "POL-ESCALATE-HIGH-RISK": {
        "action": "escalate_tier2",
        "conditions": {"user_risk_score_gt": 0.80},
        "priority": 1,
        "scope": "high_risk_users"
    }
}

def detect_policy_conflicts(alert, context) -> list[PolicyConflict]:
    """Find all applicable policies and detect conflicts."""
    applicable = [p for p in POLICIES if matches(p, alert, context)]
    conflicts = find_conflicts(applicable)  # actions disagree
    return conflicts

def resolve_conflict(conflict) -> PolicyResolution:
    """Resolve by priority, then security-first principle."""
    winner = min(conflict.policies, key=lambda p: p.priority)
    return PolicyResolution(
        winning_policy=winner,
        reason=f"Higher priority ({winner.priority}) + security-first principle",
        audit_id=generate_audit_id()
    )
```

#### Implementation Plan

| Prompt | Scope | Files |
|---|---|---|
| 9A | Backend: Policy definitions, conflict detection, resolution logic | `backend/app/services/policy.py` |
| 9B | Frontend: Policy Conflict panel in Tab 3 Situation Analyzer | `AlertTriageTab.tsx` |

**Note:** This only fires for ALERT-7823 (John Smith, risk 0.85) â€” the phishing alert has no policy conflict. This makes the demo narrative richer: "Same system, different alert, different reasoning path."

---

### 1D. Prompt Hub with Executive Error Recovery

**Priority:** Medium â€” improves Tab 1 usability and demonstrates governed analytics.

**The Problem:** When an exec types "how are we doing" into Tab 1, the system returns nothing or a poor match. There's no recovery path.

**The Solution:** A Prompt Hub layer between the user query and the metric matching that:
1. Normalizes vague queries to canonical metrics
2. Suggests alternatives when no exact match
3. Remembers successful queryâ†’metric mappings
4. Shows "Did you mean...?" for near-misses

#### UI Enhancement (Tab 1)

```
Current: User types â†’ instant match or nothing

Enhanced:
User types "how's security doing?"
â†’ No exact match
â†’ "Did you mean one of these?"
   â€¢ "Show MTTR by severity" (Mean Time to Respond)
   â€¢ "Show auto-close rate" (Alert Resolution Efficiency)
   â€¢ "Show analyst efficiency" (Alerts per Analyst per Day)
â†’ User clicks one â†’ result displays
â†’ Mapping saved: "how's security doing" â†’ [mttr, auto_close, analyst_efficiency]
â†’ Next time same query â†’ shows all three
```

#### Implementation Plan

| Prompt | Scope | Files |
|---|---|---|
| 10A | Backend: Fuzzy matching + suggestion engine + mapping store | `backend/app/services/prompt_hub.py` + `backend/app/routers/soc.py` |
| 10B | Frontend: "Did you mean?" suggestions + saved queries panel | `SOCAnalyticsTab.tsx` |

---

### v2.5 Priority Matrix

| Feature | CISO Impact | VC Impact | Demo Wow | Effort | Priority |
|---|---|---|---|---|---|
| **ROI Calculator** | ðŸ”´ Very High | ðŸŸ¡ Medium | ðŸ”´ Very High | 3 prompts | **P0** |
| **Outcome Feedback** | ðŸ”´ Very High | ðŸ”´ Very High | ðŸ”´ Very High | 2 prompts | **P1** |
| **Policy Conflict** | ðŸ”´ Very High | ðŸŸ¡ Medium | ðŸ”´ Very High | 2 prompts | **P1** |
| **Prompt Hub** | ðŸŸ¡ Medium | ðŸŸ¢ Low | ðŸŸ¡ Medium | 2 prompts | **P2** |

**Recommended build order:** ROI Calculator â†’ Outcome Feedback â†’ Policy Conflict â†’ Prompt Hub

---

## SECTION 2: v3.0 â€” Platform Depth

**Theme:** "From demo to platform. From one copilot to many. From SOC to enterprise."
**Estimated effort:** Multiple sessions, architecture changes required
**Target:** VC pitch deck proof points, enterprise pilot readiness

---

### 2A. Full Reinforcement Learning on Decision Graph

**What v2.5's Outcome Feedback started, v3.0 completes.**

v2.5 adds manual feedback buttons (correct/incorrect). v3.0 adds **automated outcome detection**:

| Signal | Source | What It Means |
|---|---|---|
| Alert re-opened within 24h | SIEM | Auto-close was wrong |
| No re-open after 7 days | SIEM | Auto-close was correct |
| Analyst overrides decision | SOC workflow | System needs recalibration |
| Escalation resolved as FP | Ticket system | Could have been auto-closed |
| Incident confirmed from alert | IR platform | Alert was real, system was right to escalate |

#### Architecture: Decision Graph as a Learning Surface

```
Current (v2.0):
  Alert â†’ Decision â†’ Action â†’ Done

v3.0:
  Alert â†’ Decision â†’ Action â†’ Outcome Observation
                                    â†“
                              Outcome Signal
                                    â†“
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚                     â”‚
                    Positive Signal        Negative Signal
                          â”‚                     â”‚
                    Strengthen Path        Weaken Path
                    â€¢ Edge weight +0.02   â€¢ Edge weight -0.05
                    â€¢ Confidence +0.3%    â€¢ Confidence -2%
                    â€¢ Add to precedents   â€¢ Flag for review
                          â”‚                     â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                          Graph State Updated
                                    â†“
                          Next Decision Benefits
```

#### Key Technical Decisions

1. **Asymmetric learning rate** â€” negative outcomes have 2-3x the impact of positive outcomes (safety-first)
2. **Confidence floor** â€” patterns can never drop below 50% confidence (prevents oscillation)
3. **Human-in-the-loop trigger** â€” if confidence drops >10% in a week, auto-escalate all matching alerts until analyst reviews
4. **Temporal decay** â€” old outcomes matter less (6-month half-life)

#### What This Enables (VC Narrative)

"Every other AI security vendor starts from zero with each customer. Our graph accumulates intelligence. And not just from rule updates â€” from actual outcomes. The same alert that failed six months ago? The system remembers and handles it differently now. That's not a feature. That's a moat."

---

### 2B. External Context Ingestion

**The Problem:** The context graph only knows what's in the SIEM and Neo4j seed data. Real SOC decisions depend on context from many sources.

**The Vision:** The UCL's CONSUME pattern, applied to external sources.

#### Context Sources

| Source | What It Provides | Integration |
|---|---|---|
| **Threat Intelligence Feeds** (MITRE ATT&CK, CISA) | Known attack patterns, IOCs, TTPs | API polling â†’ new AttackPattern nodes |
| **Email/Slack** (via Rowboat Labs-style tools) | Internal context ("we're seeing phishing targeting finance") | NLP extraction â†’ context annotations |
| **Meeting Transcripts** | SOC standup notes, IR debrief decisions | Summarization â†’ decision precedents |
| **Vulnerability Scanners** (Qualys, Tenable) | Asset risk context | Enrichment â†’ Asset node properties |
| **HR Systems** | Role changes, departures, new hires | User context updates â†’ risk recalculation |
| **Travel/Expense** (Concur, SAP) | Travel plans, locations | Travel context â†’ existing pattern support |

#### Demo Enhancement

Tab 1 or Tab 3 could show a "Context Sources" indicator:

```
Context Graph: 247 nodes
  â”œâ”€â”€ SIEM data: 189 nodes
  â”œâ”€â”€ Threat Intel: 31 nodes (MITRE ATT&CK)
  â”œâ”€â”€ Slack alerts: 12 nodes (SOC channel, 24h)
  â”œâ”€â”€ HR system: 8 nodes (recent role changes)
  â””â”€â”€ Vuln scanner: 7 nodes (critical CVEs)

Last refresh: 3 minutes ago
```

This makes the graph feel **alive** â€” it's not a static database but an actively updated context layer.

#### Architecture

```
External Sources â†’ Ingestion Layer â†’ UCL Graph
                        â†“
                  CONSUME operation
                        â†“
                  Node creation/update
                        â†“
                  Freshness tracking
                        â†“
                  Available to all queries
```

**Key principle:** The ingestion layer is CONSUME-only. It adds context. It never makes decisions or takes actions. The decision layer (Situation Analyzer, Agent) reads the enriched graph.

---

### 2C. CISO Domain Depth â€” Compliance & Alert Volume

Two specific CISO pain points that v2.0 doesn't address:

#### 2C-1. Compliance & Audit Trail (Evidence Ledger)

**The Problem:** CISOs report to boards quarterly. They need to prove: "Our security posture improved. Here's the evidence." Current tools give them dashboards. They need **auditable decision records**.

**The Solution:** An Evidence Ledger â€” every decision creates an immutable record:

```
Evidence Record: EVD-2026-08472
â”œâ”€â”€ Alert: ALERT-7823
â”œâ”€â”€ Decision: FALSE_POSITIVE_CLOSE
â”œâ”€â”€ Confidence: 92%
â”œâ”€â”€ Context consulted: 47 nodes
â”œâ”€â”€ Policies evaluated: POL-AUTO-CLOSE-TRAVEL, POL-ESCALATE-HIGH-RISK
â”œâ”€â”€ Conflict resolution: POL-ESCALATE-HIGH-RISK (priority)
â”œâ”€â”€ Eval gate: PASSED (4/4 checks, overall 0.97)
â”œâ”€â”€ Outcome: Confirmed correct (7 days, no re-open)
â”œâ”€â”€ Graph impact: PAT-TRAVEL-001 confidence +0.3%
â””â”€â”€ Timestamp: 2026-02-17T14:32:01Z (7-year retention)
```

**Demo enhancement:** A "Compliance Export" button on Tab 4 that generates a sample evidence report showing how every decision is traceable from alert â†’ context â†’ reasoning â†’ action â†’ outcome.

**Mapping to standards:** SOC2 Type II (decision traceability), NIST CSF (continuous monitoring evidence), ISO 27001 (information security management records).

#### 2C-2. Alert Volume Simulation

**The Problem:** The demo processes one alert at a time. CISOs deal with 5,000-50,000 alerts/day. They need to see that the system handles volume, not just quality.

**The Solution:** An "Alert Volume Simulation" mode on Tab 4 that shows:

```
Simulation: 500 alerts/day over 4 weeks

Week 1: 500 alerts â†’ 175 auto-handled (35%) â†’ 325 need humans â†’ 41 analyst-hours/day
Week 2: 500 alerts â†’ 290 auto-handled (58%) â†’ 210 need humans â†’ 26 analyst-hours/day
Week 3: 500 alerts â†’ 380 auto-handled (76%) â†’ 120 need humans â†’ 15 analyst-hours/day
Week 4: 500 alerts â†’ 445 auto-handled (89%) â†’ 55 need humans  â†’ 7 analyst-hours/day

Analyst capacity freed: 34 hours/day (4.25 FTEs)
```

This directly connects to the ROI Calculator (v2.5) â€” the simulation provides the proof that the calculator's projections are realistic.

---

### 2D. Process Intelligence Integration (UCL + Celonis)

**The Big Idea:** Nobody has extracted meaningful process intelligence data from tools like Celonis and made it part of a context graph's semantics. This is a unique architectural contribution.

#### What Process Mining Provides

Process mining tools (Celonis, Microsoft Process Advisor, UiPath Process Mining) extract:

| Data | What It Shows | Graph Representation |
|---|---|---|
| **Process variants** | How alerts actually flow through the SOC | Paths through the decision graph |
| **Bottleneck analysis** | Where alerts get stuck | High-latency edges in the graph |
| **Conformance checking** | Are analysts following playbooks? | Deviation nodes linked to decisions |
| **Rework loops** | How often are alerts re-opened? | Cycle detection in the graph |
| **Resource utilization** | Which analysts handle which alert types? | Analystâ†’AlertType affinity edges |

#### The Integration Vision

```
Process Mining Layer (Celonis/etc.)
        â†“
  Extracts: process variants, bottlenecks, deviations
        â†“
  Transforms to: ProcessVariant nodes, Bottleneck nodes, Deviation nodes
        â†“
UCL Context Graph
  â”œâ”€â”€ Existing: Alerts, Users, Assets, Patterns, Decisions
  â””â”€â”€ NEW: ProcessVariant, Bottleneck, Deviation, AnalystAffinity
        â†“
  Enriched queries:
  "Not just WHAT happened, but HOW it flowed and WHERE it got stuck"
```

#### Demo Example

Tab 4 could show a "Process Flow" view:

```
Travel Login Alerts â€” Process Variants

Variant A (82% of cases): Detect â†’ Auto-classify â†’ Auto-close â†’ Verify
  Avg time: 3 seconds | Outcome: 97% correct

Variant B (12% of cases): Detect â†’ Auto-classify â†’ Escalate â†’ Manual Review â†’ Close
  Avg time: 45 minutes | Bottleneck: Manual Review (38 min wait)
  Insight: "These could be auto-closed â€” missing VPN context"

Variant C (6% of cases): Detect â†’ Auto-classify â†’ Auto-close â†’ Re-open â†’ Investigate
  Avg time: 4.2 hours | Rework loop detected
  Insight: "Auto-close threshold too aggressive for risk > 0.80 users"
```

The copilot uses this to **optimize its own process**: "I see that Variant B has a 38-minute bottleneck because of missing VPN context. If I add VPN checking to my auto-classify step, 80% of Variant B alerts could follow Variant A's 3-second path."

#### Why This Is Unique

1. **Nobody has done this** â€” process mining and AI agents are separate worlds today
2. **UCL makes it possible** â€” the semantic graph is the natural convergence point
3. **It's measurable** â€” process variant shift from Bâ†’A is a concrete, provable improvement
4. **CISOs understand it** â€” they've seen process mining in supply chain; applying it to SOC is novel but intuitive

#### Relationship to the Common Semantic Layer

The UCL blog describes the common semantic layer as the substrate that BI, ML, RAG, and agents all consume. Process intelligence is a new CONSUME source:

```
Common Semantic Layer (UCL)
  â”œâ”€â”€ CONSUME from: SIEM, EDW, Process Mining, Threat Intel, HR
  â”œâ”€â”€ SERVE to: BI dashboards, ML models, RAG pipelines, Agents
  â”œâ”€â”€ MUTATE via: Agent decisions, Outcome feedback, Pattern learning
  â””â”€â”€ ACTIVATE through: Closed-loop execution, Playbook triggers
```

Process mining data becomes first-class graph semantics â€” not just an analytics overlay, but context that agents reason over.

---

### 3B. Process Intelligence + Semantic Layer Convergence (Vision)

**This is the long-term differentiator for VC conversations.**

The thesis: **The enterprise semantic layer and process intelligence are converging.** Today they're separate:
- Semantic layer (dbt, Atlan, Alation) = data definitions
- Process mining (Celonis, Microsoft) = workflow analysis
- AI agents (us) = decision automation

Nobody has connected all three. The UCL does.

```
Current Market (Disconnected):

  Semantic Layer â†â†’ BI Dashboards
  Process Mining â†â†’ Process Optimization
  AI Agents     â†â†’ Task Automation

UCL Vision (Connected):

  Semantic Layer â”€â”
  Process Mining â”€â”€â”¼â”€â”€â†’ UCL Context Graph â”€â”€â†’ Agents that reason over
  AI Outcomes    â”€â”€â”˜                          BOTH data semantics AND
                                              process dynamics
```

#### The Competitive Moat

This convergence is defensible because:

1. **Data + Process + Decisions** in one graph creates network effects no single vendor can replicate
2. **Cross-domain compounding** â€” SOC process patterns inform supply chain patterns and vice versa
3. **Temporal depth** â€” the graph accumulates months of process intelligence, creating a historical reasoning substrate
4. **Standards alignment** â€” maps to OCSF (Open Cybersecurity Schema Framework), BPMN (process notation), and semantic web standards

#### VC Pitch Line

> "Everyone's building AI agents. We're building the substrate they reason over. When process intelligence, data semantics, and decision outcomes converge in one graph, you get agents that don't just decide â€” they understand WHY the process works the way it does. That's not an agent. That's institutional intelligence."

---

## Implementation Roadmap

### v2.5 Sequence (Next 2-3 Sessions)

```
Session A: ROI Calculator
  Prompt 7A: Backend â€” /api/roi/calculate endpoint
  Prompt 7B: Frontend â€” ROI Calculator modal with sliders
  Prompt 7C: Tab 4 integration + PDF export button
  â†’ Commit, test, push

Session B: Outcome Feedback + Policy Conflict
  Prompt 8A: Backend â€” /api/alert/outcome endpoint + feedback service
  Prompt 8B: Frontend â€” Outcome Feedback panel in Tab 3
  Prompt 9A: Backend â€” Policy service with conflict detection
  Prompt 9B: Frontend â€” Policy Conflict panel in Tab 3
  â†’ Commit, test, push

Session C (optional): Prompt Hub + Polish
  Prompt 10A: Backend â€” Fuzzy matching + suggestion engine
  Prompt 10B: Frontend â€” "Did you mean?" in Tab 1
  â†’ Commit, test, push
  â†’ Tag v2.5, update docs
```

### v3.0 Sequence (Longer-Term)

```
Phase 1: Reinforcement Learning on Graph
  - Automated outcome detection
  - Asymmetric learning rates
  - Confidence management
  - Temporal decay

Phase 2: External Context Ingestion
  - Threat intel feed integration
  - Freshness tracking
  - Context source indicators

Phase 3: Compliance & Evidence Ledger
  - Immutable decision records
  - Compliance report export
  - Standards mapping (SOC2, NIST, ISO)

Phase 4: Process Intelligence Integration
  - Process variant extraction
  - Bottleneck detection
  - Graph node creation from process data
  - Agent self-optimization from process insights

Phase 5: Multi-Domain Extension
  - Second copilot (Supply Chain or Finance)
  - Cross-domain graph sharing via UCL
  - Compounding across copilots
```

---

## Appendix: Key Soundbites by Audience

### For CISOs

| Feature | Soundbite |
|---|---|
| ROI Calculator | "Plug in your numbers. See your savings. Take this to your CFO." |
| Outcome Feedback | "When it's wrong, it learns. When it's right, it gets more confident. Your playbooks don't do that." |
| Policy Conflict | "You have conflicting policies right now. You just don't know it. We find them, resolve them, and audit the resolution." |
| Evidence Ledger | "Board meeting in two weeks? Here's every decision, every outcome, every improvement â€” automatically generated." |
| Process Intelligence | "We don't just automate your SOC. We show you WHY alerts take 45 minutes when they should take 3 seconds." |

### For VCs

| Feature | Soundbite |
|---|---|
| Decision Graph Learning | "Every decision makes the graph smarter. Every outcome validates or corrects. Competitors start at zero. We start at 10,000 validated decisions." |
| UCL + Process Intelligence | "Everyone's building agents. We're building the substrate â€” data semantics, process dynamics, and decision outcomes in one graph. That's institutional intelligence." |
| Multi-Domain Compounding | "SOC copilot learns a pattern. Finance copilot inherits the reasoning structure. Same graph, compounding across domains. That's a platform, not a product." |
| Convergence Thesis | "Semantic layers, process mining, and AI agents are converging. We're the wiring between them. That's not a feature gap â€” it's an architectural gap." |

---

*SOC Copilot Demo v2.5/v3.0 Design Document v1.0 | February 17, 2026*
*Status: Draft â€” Design Phase*
*Next action: Session A (ROI Calculator) when ready to build*
