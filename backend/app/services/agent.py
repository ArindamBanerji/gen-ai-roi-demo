"""
SOC Copilot Agent - Simple Rule-Based Decision Engine
~150 lines total. The demo proves the ARCHITECTURE, not agent sophistication.

The agent is intentionally simple because:
1. Demo reliability - Same decision every time
2. Auditability - CISOs need to explain decisions
3. Faster build - Focus on architecture
4. Clear separation - Architecture proves the thesis, not AI magic
"""
from typing import Dict, Any, Optional, Tuple
from datetime import datetime
import uuid


class DecisionResult:
    """Agent decision output"""

    def __init__(
        self,
        action: str,
        confidence: float,
        pattern_id: Optional[str] = None,
        playbook_id: Optional[str] = None,
    ):
        self.action = action
        self.confidence = confidence
        self.pattern_id = pattern_id
        self.playbook_id = playbook_id


class SOCAgent:
    """
    Simple rule-based SOC decision engine.
    No LLM orchestration - just deterministic rules.
    """

    # Action types
    ACTION_FALSE_POSITIVE_CLOSE = "false_positive_close"
    ACTION_AUTO_REMEDIATE = "auto_remediate"
    ACTION_ENRICH_AND_WAIT = "enrich_and_wait"
    ACTION_ESCALATE_TIER2 = "escalate_tier2"
    ACTION_ESCALATE_INCIDENT = "escalate_incident"

    def decide(self, alert_type: str, context: Dict[str, Any]) -> DecisionResult:
        """
        Main decision function. Rule-based logic.

        Args:
            alert_type: Type of alert (anomalous_login, phishing, malware_detection, data_exfiltration)
            context: Security context from graph traversal

        Returns:
            DecisionResult with action, confidence, pattern_id, playbook_id
        """

        # ====================================================================
        # Rule 1: Anomalous Login
        # ====================================================================
        if alert_type == "anomalous_login":
            # Priority 1: Check for travel context (most specific)
            # If user is traveling to the alert location, it's likely legitimate
            user_traveling = context.get("user_traveling", False)
            vpn_matches = context.get("vpn_matches_location", False)
            mfa_completed = context.get("mfa_completed", False)
            device_match = context.get("device_fingerprint_match", False)
            risk_score = context.get("user_risk_score", 0.0)

            # Debug logging
            print(f"[AGENT] Anomalous login decision for user {context.get('user_name')}")
            print(f"  - user_traveling: {user_traveling}")
            print(f"  - vpn_matches_location: {vpn_matches}")
            print(f"  - mfa_completed: {mfa_completed}")
            print(f"  - device_fingerprint_match: {device_match}")
            print(f"  - user_risk_score: {risk_score}")
            print(f"  - travel_destination: {context.get('travel_destination')}")

            # Strong travel match - all indicators align
            if user_traveling and vpn_matches and mfa_completed and device_match:
                return DecisionResult(
                    action=self.ACTION_FALSE_POSITIVE_CLOSE,
                    confidence=0.92,
                    pattern_id="PAT-TRAVEL-001",
                    playbook_id="PB-LOGIN-FP"
                )

            # Good travel match - user traveling + location matches (even without all other checks)
            if user_traveling and vpn_matches:
                return DecisionResult(
                    action=self.ACTION_FALSE_POSITIVE_CLOSE,
                    confidence=0.88,
                    pattern_id="PAT-TRAVEL-001",
                    playbook_id="PB-LOGIN-FP"
                )

            # Moderate travel match - traveling but location uncertain
            if user_traveling and (mfa_completed or device_match):
                return DecisionResult(
                    action=self.ACTION_FALSE_POSITIVE_CLOSE,
                    confidence=0.82,
                    pattern_id="PAT-TRAVEL-001",
                    playbook_id="PB-LOGIN-FP"
                )

            # Priority 2: High risk user WITHOUT travel context
            # Only escalate if there's no travel explanation
            if context.get("user_risk_score", 0.0) > 0.8 and not user_traveling:
                return DecisionResult(
                    action=self.ACTION_ESCALATE_INCIDENT,
                    confidence=0.95,
                    playbook_id="PB-INCIDENT"
                )

            # Default: escalate to tier 2 for manual review
            return DecisionResult(
                action=self.ACTION_ESCALATE_TIER2,
                confidence=0.78,
                playbook_id="PB-LOGIN-T2"
            )

        # ====================================================================
        # Rule 2: Phishing
        # ====================================================================
        elif alert_type == "phishing":
            # Known campaign signature
            if context.get("known_campaign_signature"):
                return DecisionResult(
                    action=self.ACTION_AUTO_REMEDIATE,
                    confidence=0.94,
                    pattern_id="PAT-PHISH-KNOWN",
                    playbook_id="PB-PHISH-AUTO"
                )

            # Unknown phishing - escalate
            return DecisionResult(
                action=self.ACTION_ESCALATE_TIER2,
                confidence=0.85,
                playbook_id="PB-PHISH-T2"
            )

        # ====================================================================
        # Rule 3: Malware Detection
        # ====================================================================
        elif alert_type == "malware_detection":
            # Critical asset - always escalate
            if context.get("asset_criticality") == "critical":
                return DecisionResult(
                    action=self.ACTION_ESCALATE_INCIDENT,
                    confidence=0.96,
                    playbook_id="PB-MALWARE-CRIT"
                )

            # Non-critical - auto-remediate (isolate)
            return DecisionResult(
                action=self.ACTION_AUTO_REMEDIATE,
                confidence=0.89,
                pattern_id="PAT-MALWARE-ISOLATE",
                playbook_id="PB-MALWARE-AUTO"
            )

        # ====================================================================
        # Rule 4: Data Exfiltration (Always escalate)
        # ====================================================================
        elif alert_type == "data_exfiltration":
            return DecisionResult(
                action=self.ACTION_ESCALATE_INCIDENT,
                confidence=0.97,
                playbook_id="PB-DLP-INCIDENT"
            )

        # ====================================================================
        # Default: Escalate to tier 2
        # ====================================================================
        return DecisionResult(
            action=self.ACTION_ESCALATE_TIER2,
            confidence=0.60,
            playbook_id="PB-DEFAULT-T2"
        )

    def _calculate_faithfulness(
        self,
        decision: DecisionResult,
        context: Dict[str, Any],
        reasoning: str
    ) -> float:
        """
        Calculate faithfulness score: Does reasoning match decision and context?

        Returns a score between 0.0 and 1.0
        """
        reasoning_lower = reasoning.lower()
        score = 0.60  # Base score

        # Check 1: Action keyword appears in reasoning (basic alignment)
        action_keywords = {
            self.ACTION_FALSE_POSITIVE_CLOSE: ["false positive", "legitimate", "expected", "travel", "authorized"],
            self.ACTION_AUTO_REMEDIATE: ["remediate", "isolate", "quarantine", "contain"],
            self.ACTION_ESCALATE_INCIDENT: ["incident", "critical", "escalate", "security team"],
            self.ACTION_ESCALATE_TIER2: ["review", "investigate", "analyst", "tier 2"],
            self.ACTION_ENRICH_AND_WAIT: ["context", "information", "gather", "enrich"],
        }

        if decision.action in action_keywords:
            for keyword in action_keywords[decision.action]:
                if keyword in reasoning_lower:
                    score = 0.88  # Good alignment
                    break

        # Check 2: Pattern-specific reasoning (strong alignment)
        if decision.pattern_id:
            pattern_keywords = {
                "PAT-TRAVEL-001": ["travel", "traveling", "trip", "location", "destination", "singapore"],
                "PAT-PHISH-KNOWN": ["phishing", "campaign", "known", "signature"],
                "PAT-MALWARE-ISOLATE": ["malware", "isolate", "infected"],
            }

            if decision.pattern_id in pattern_keywords:
                for keyword in pattern_keywords[decision.pattern_id]:
                    if keyword in reasoning_lower:
                        score = 0.94  # Strong alignment with pattern
                        break

        # Check 3: Context-aware reasoning (excellent alignment)
        # If decision is based on travel, reasoning should mention travel details
        if decision.pattern_id == "PAT-TRAVEL-001" and decision.action == self.ACTION_FALSE_POSITIVE_CLOSE:
            travel_indicators = 0
            if context.get("travel_destination") and context["travel_destination"].lower() in reasoning_lower:
                travel_indicators += 1
            if "travel" in reasoning_lower or "traveling" in reasoning_lower:
                travel_indicators += 1
            if "vpn" in reasoning_lower or "location" in reasoning_lower:
                travel_indicators += 1
            if "mfa" in reasoning_lower or "auth" in reasoning_lower:
                travel_indicators += 1

            # Award score based on how many travel indicators are mentioned
            if travel_indicators >= 3:
                score = 0.96  # Excellent - mentions travel + location + verification
            elif travel_indicators >= 2:
                score = 0.92  # Very good - mentions key travel context
            elif travel_indicators >= 1:
                score = 0.88  # Good - mentions travel

        # Debug logging
        print(f"[FAITHFULNESS] Score: {score:.2f}")
        print(f"  - Decision: {decision.action}")
        print(f"  - Pattern: {decision.pattern_id}")
        print(f"  - Reasoning mentions travel: {'travel' in reasoning_lower}")

        return score

    def evaluate_gates(
        self,
        decision: DecisionResult,
        context: Dict[str, Any],
        reasoning: str
    ) -> Dict[str, Any]:
        """
        Evaluate 4 deterministic eval gates.
        All are deterministic checks - no LLM scoring.

        Returns dict with checks and overall pass/fail
        """

        checks = []

        # ================================================================
        # Gate 1: Faithfulness (Does reasoning match decision?)
        # ================================================================
        # Check if reasoning aligns with decision and context
        faithfulness_score = self._calculate_faithfulness(decision, context, reasoning)

        checks.append({
            "name": "Faithfulness",
            "score": faithfulness_score,
            "threshold": 0.85,
            "passed": faithfulness_score >= 0.85,
            "message": "Reasoning matches recommended action and context"
        })

        # ================================================================
        # Gate 2: Safe Action (Is action safe for asset criticality?)
        # ================================================================
        # Block auto-remediate on critical assets
        asset_crit = context.get("asset_criticality", "medium")
        safe_action_score = 1.0

        if decision.action == self.ACTION_AUTO_REMEDIATE and asset_crit == "critical":
            safe_action_score = 0.0

        checks.append({
            "name": "Safe Action",
            "score": safe_action_score,
            "threshold": 1.0,
            "passed": safe_action_score >= 1.0,
            "message": "Action is safe for asset criticality"
        })

        # ================================================================
        # Gate 3: Playbook Match (Does decision follow playbook?)
        # ================================================================
        # Simplified: Check if playbook_id is set
        playbook_match_score = 0.94 if decision.playbook_id else 0.70
        checks.append({
            "name": "Playbook Match",
            "score": playbook_match_score,
            "threshold": 0.80,
            "passed": playbook_match_score >= 0.80,
            "message": "Decision follows approved playbook"
        })

        # ================================================================
        # Gate 4: SLA Compliance (Can we meet SLA?)
        # ================================================================
        # Simplified: Always passes for auto actions, lower for manual
        sla_score = 0.98 if decision.action in [
            self.ACTION_FALSE_POSITIVE_CLOSE,
            self.ACTION_AUTO_REMEDIATE
        ] else 0.92

        checks.append({
            "name": "SLA Compliance",
            "score": sla_score,
            "threshold": 0.90,
            "passed": sla_score >= 0.90,
            "message": "Action meets SLA requirements"
        })

        # Overall verdict
        all_passed = all(check["passed"] for check in checks)
        overall_score = sum(check["score"] for check in checks) / len(checks)

        return {
            "checks": checks,
            "overall_passed": all_passed,
            "overall_score": overall_score,
        }

    def maybe_trigger_evolution(
        self,
        decision: DecisionResult,
        context: Dict[str, Any]
    ) -> Optional[Tuple[str, Dict[str, Any]]]:
        """
        Determine if this decision should trigger an evolution event.

        Returns:
            Tuple of (event_type, evolution_details) if evolution should occur
            None if no evolution
        """

        # Evolution trigger: Pattern-based decisions with high occurrence count
        if decision.pattern_id and context.get("pattern_count", 0) > 100:
            # Increase pattern confidence
            old_fp_rate = context.get("fp_rate", 0.20)
            new_fp_rate = max(0.05, old_fp_rate - 0.03)  # Reduce FP rate by 3%

            return (
                "pattern_confidence",
                {
                    "pattern_id": decision.pattern_id,
                    "before": {"fp_rate": old_fp_rate, "confidence": 0.91},
                    "after": {"fp_rate": new_fp_rate, "confidence": 0.94},
                    "description": f"Pattern {decision.pattern_id} confidence increased: 91% â†’ 94% (+3 pts)",
                    "impact": "medium",
                    "magnitude": 0.03,
                }
            )

        return None


# Global agent instance
agent = SOCAgent()
